{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkLearn Recipes.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "C8gHrTE_l6dI"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaushil24/DS-Cookbook101/blob/master/SkLearn_Recipes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bczyGbIWzzqE",
        "colab_type": "text"
      },
      "source": [
        "# Some sklearn recieps:\n",
        "* Train test split\n",
        "* Linear Regression Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUVn7ALetAm1",
        "colab_type": "text"
      },
      "source": [
        "# Scikitlearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuz7-xa-OwJz",
        "colab_type": "text"
      },
      "source": [
        "## One Hot Encoding\n",
        "Difference between when to use sklearn's OneHotEncoder vs pandas' get_dummies() [here](https://stackoverflow.com/a/56567037/13201804)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLiRvrk9PHaz",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "col_name = 'name of column to encode'\n",
        "enc = OneHotEncoder(handle_unknown= 'ignore')\n",
        "enc.fit( df.loc[ :, [col_name]] )\n",
        "# Print the categories: enc.categories_\n",
        "encoded = enc.transform( df.loc[:, ['col_name']] ).toarray() \n",
        "for i, category in enumerate(enc.categories_[0]):\n",
        "    df[category] = encoded[:, i]\n",
        "\n",
        "df.drop(col_name, axis = 1, inplace = True)\n",
        "df.head()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_KNxxGetGPi",
        "colab_type": "text"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNaiSwBZ0jCi",
        "colab_type": "text"
      },
      "source": [
        "``` \n",
        "from sklearn.model_selection import train_test_split\n",
        "trainX, testX, trainY, testY = train_test_split(df1[df1.columns.drop('label_col')], df1['label_col'], test_size=0.2)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx71Xntc0wb1",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n4UeMSI036g",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from sklearn.linear_model import LinearRegression\n",
        "reg = LinearRegression()\n",
        "reg.fit(trainX, trainY)\n",
        "reg.score(trainX, trainY)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIegYrMe4RS9",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbl-GBk_4XsJ",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "mdl = LogisticRegression()\n",
        "mdl.fit(trainX, trainY)\n",
        "mdl.score(testX, testY)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvQ7Ey5HdImY",
        "colab_type": "text"
      },
      "source": [
        "## SVM\n",
        "[docs](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYS9k_oCdLEl",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = SVC() #select the algorithm\n",
        "model.fit(train_X,train_y) # we train the algorithm with the training data and the training output\n",
        "prediction=model.predict(test_X) #now we pass the testing data to the trained algorithm\n",
        "print('The accuracy of the SVM is:',accuracy_score(prediction,test_y))#now we check the accuracy of the algorithm. \n",
        "#we pass the predicted output by the model and the actual output\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1wTwvav9waH",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree\n",
        "Training and visualizing a decision tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F0tXUo09y6X",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from sklearn import tree\n",
        "# from IPython.display import Image  \n",
        "import graphviz\n",
        "\n",
        "clf_decTree = DecisionTreeClassifier()\n",
        "clf_decTree.fit(trainX, trainy)\n",
        "\n",
        "dot_data = tree.export_graphviz(clf_decTree, out_file=None, \n",
        "                     feature_names=trainX.columns,  \n",
        "                     class_names=['Stress', 'Not Stress'],  \n",
        "                     filled=True, rounded=True,  \n",
        "                     special_characters=True)\n",
        "\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph # Display the graph\n",
        "graph.format = 'png'\n",
        "graph.render('file_name',view=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afl1dx4H-GLX",
        "colab_type": "text"
      },
      "source": [
        "## Getting train and test accuracy of a classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfSDRsT4-L-S",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from sklearn.metrics import accuracy_score\n",
        "score_train = clf.score(trainX, trainy)\n",
        "y_pred = clf.predict(testX)\n",
        "print(f'Train Accuracy : {score_train*100} %')\n",
        "score_test = accuracy_score(y_pred, testy)\n",
        "print(f'Test Accuracy: {score_test*100} %')\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8gHrTE_l6dI",
        "colab_type": "text"
      },
      "source": [
        "# Bonus Recipes \n",
        "Some random hacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WYxktK1mRn3",
        "colab_type": "text"
      },
      "source": [
        "## Remove positive distribution\n",
        "<h3> Apply log function to convert positively skewed distribution into a gaussian normal distribution "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0nRFSSImdgn",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "from scipy import stats\n",
        "df['col'] = np.log(df['col'])\n",
        "sns.distplot(df['col'], fit=norm)\n",
        "stats.probplot(df_train['GrLivArea'], plot=plt)\n",
        "```"
      ]
    }
  ]
}